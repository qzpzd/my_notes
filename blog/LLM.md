# 大模型（LLMs）进阶面
## 1. 目前主流的开源模型体系有哪些？

   当谈到主流的开源模型体系时，以下是一些备受关注和广泛使用的体系和模型：

   - **Hugging Face Transformers**: Hugging Face的Transformers库是自然语言处理领域中最受欢迎的开源模型体系之一。它包含了各种预训练模型，包括BERT、GPT、RoBERTa等，并提供了易于使用的API。

   - **OpenAI GPT-3**: GPT-3是由OpenAI开发的一种大型语言模型。虽然它不是完全开源的，但其API被广泛使用，用于各种自然语言处理任务。

   - **PyTorch**: PyTorch是一个深度学习框架，也有许多开源的自然语言处理模型和库，如TorchText和TorchScript。

   - **Google BERT**: BERT是由Google开发的预训练模型，已经在自然语言处理中取得了巨大的成功。虽然Google没有提供官方的Python库，但开发社区创建了多个开源实现。

   - **Facebook Fairseq**: Fairseq是Facebook AI Research开发的开源序列到序列模型库，用于机器翻译和其他自然语言处理任务。

   - **AllenNLP**: AllenNLP是由Allen Institute for AI开发的深度学习库，专注于自然语言处理任务，提供了众多预训练模型和工具。

   这些是当前自然语言处理领域中主要的开源模型体系，每个体系都有其独特的模型和工具，适用于各种自然语言处理任务。

## 2. Prefix LM 和 causal LM 区别是什么？

   - **Prefix LM (PLM)**: Prefix LM是一种语言模型，它在生成文本时考虑了前缀（prefix）。前缀是指输入文本的一部分，它在生成输出时作为提示或指导信息被提供给模型。这使得PLM更容易控制和引导生成的文本，因为模型知道应该以给定的前缀开始生成文本。

   - **Causal LM (CLM)**: Causal LM是一种自回归语言模型，它生成文本的每个令牌时只考虑了已生成的令牌，而不考虑后续令牌。这使得CLM在生成文本时通常是单向的，它根据之前生成的令牌来预测下一个令牌。GPT模型就是一种典型的Causal LM。

   总的来说，PLM考虑了前缀来引导生成，而CLM是自回归模型，仅考虑已生成的令牌。它们在文本生成任务中有不同的应用场景和特性。

## 3. 涌现能力是啥原因？

   "涌现能力"是指大型语言模型在生成文本时表现出的创造力和能够生成具有上下文相关性的自然文本的能力。这种能力的原因可以归结为以下几点：

   - **数据量**: 大型语言模型通常在庞大的文本数据集上进行了预训练，这使它们能够学习大量的语言知识和语言模式。

   - **模型架构**: 深度神经网络模型，特别是变换器架构（如BERT和GPT），具有大量的参数和多层结构，能够捕获文本中的复杂关系和上下文。

   - **自监督学习**: 这些模型经常使用自监督学习的方式进行预训练，模型通过预测输入文本中的掩盖词汇或生成下一个词汇来学习语言表示。这种方式使模型能够理解文本的结构和上下文。

   - **微调**: 在预训练之后，这些模型可以进行微调以适应特定任务，这使它们能够在生成文本时结合任务目标和上下文。

   - **大规模计算**: 现代硬件和云计算资源的可用性允许模型训练在大规模数据上，这有助于提高模型的性能和涌现能力。

## 4. 大模型LLM的架构介绍？

   "LLM" 可能是一个缩写，代表 "Large Language Model"，这类模型通常包括BERT、GPT、RoBERTa等。这些模型的架构通常基于变换器（Transformer）架构，下面是一个典型的LLM架构的介绍：

   - **输入嵌入层**: 输入文本被编码为嵌入向量，通常使用词嵌入（Word Embeddings）层来实现，将词汇映射为实数向量。

   - **Transformer编码器层**: 这是LLM的核心部分，通常包括多层Transformer编码器。编码器由多头自注意力机制（Multi-Head Self-Attention）和前馈神经网络组成，用于捕捉文本中的上下文关系和特征。

   - **位置编码**: 为了处理文本中的位置信息，位置编码被添加到嵌入向量中，以使模型能够理解词汇的位置关系。
   - **堆叠层 (续)**: LLM通常由多个编码器层叠加而成，每一层都有自注意力机制和前馈神经网络。这种层叠结构允许模型逐渐提取更高级别的特征和上下文信息。

   - **预训练任务**: 在预训练阶段，LLM通过自监督任务对大规模文本数据进行训练。通常有两种任务，如掩盖语言模型（Masked Language Modeling）和下一个句子预测（Next Sentence Prediction），这些任务有助于模型学习语言表示和理解文本结构。

   - **微调层**: 在预训练之后，LLM可以通过微调层来适应特定的任务，包括文本分类、命名实体识别、问答等。微调层通常是一个额外的神经网络层，用于将LLM的表示映射到特定任务的输出。

   - **输出层**: 输出层通常用于根据任务要求生成最终的预测或文本生成。输出可以是分类标签、生成文本的词汇概率分布等，具体取决于任务类型。

     总的来说，大模型LLM的架构基于变换器（Transformer）架构，它通过多层编码器来处理输入文本，经过预训练和微调来适应各种自然语言处理任务。这些模型在自然语言处理领域取得了显著的成功，并在多种任务上取得了前沿的性能。
# 大模型（LLMs）进阶面
   ## 1.LLMs 复读机问题
   ### 1.1什么是 LLMs 复读机问题？
      LLMs（Large Language Models）复读机问题是指大型语言模型（如GPT-3、BERT等）在文本生成任务中倾向于无目的地、反复地重复输入文本中的某个短语或句子的现象。这可能是由于模型在大规模数据上训练时学到了某种统计偏差，使得它在生成文本时倾向于选择重复的片段。复读机问题通常会导致生成的文本缺乏创造性和多样性，降低了模型的实用性和质量。
   ## 1.2为什么会出现 LLMs 复读机问题？
   - **数据偏差**：模型在大规模数据中可能遇到了大量重复的句子，这导致了模型在生成文本时模仿这种数据分布。

   - **训练数据质量**：训练数据中的低质量或包含噪声的示例可能会导致模型产生不准确或重复的输出。

   - **生成任务设置**：某些生成任务可能要求模型生成与输入文本相关的内容，这可能导致模型倾向于在输出中包含输入文本的片段。
   ### 1.3如何缓解 LLMs 复读机问题？
   - **多样性惩罚**：在训练或生成时，引入多样性惩罚，鼓励模型生成更多不同的内容，而不是简单地复制输入文本。

   - **后处理**：生成的文本可以进行后处理，例如去除重复的内容或引入额外的多样性。

   - **改进数据质量**：确保训练数据的质量，避免低质量或重复示例的影响。

   - **任务设置**：根据具体任务的要求，调整模型的输入提示或目标函数，以鼓励生成与输入文本相关但不完全相同的内容。
   ## 2.LLaMA 系列问题
      LLaMA（Language Model for Many Applications） 是一种通用语言模型，旨在适用于多种自然语言处理任务。与一些专门用途的模型不同，LLaMA被设计为一种通用工具，适用于各种任务。

   LLaMA输入句子长度理论上可以很长，但实际上会受到硬件和资源的限制。GPU或TPU内存的限制可能会限制模型处理非常长的文本。在处理超长文本时，可以考虑以下方法：

   - **切分文本**：将长文本切分成较小的片段，然后分别处理这些片段，最后进行整合。

   - **滑动窗口**：通过滑动窗口的方式，将模型应用于文本的不同部分，以捕捉全文的上下文。

   - **注意力机制**：模型可以通过自注意力机制来关注与特定任务相关的上下文部分，而不是整个文本。
   
   - **硬件升级：使用更强大的硬件资源，如更大内存的GPU或分布式计算集群，以处理更长的文本。
   ## 3.什么情况用Bert模型，什么情况用LLaMA、ChatGLM类大模型，咋选？
      选择使用BERT、LLaMA或ChatGLM等模型通常取决于以下因素：

   - **任务类型**：对于一些经典的自然语言处理任务，如文本分类、命名实体识别，BERT可能是一个不错的选择。对于生成任务，如文本生成、对话系统，ChatGLM和LLaMA可以更适合。

   - **需求**：考虑你的任务需求，包括性能、速度、模型大小等。不同的模型在这些方面有不同的特性。

   - **可用数据**：不同的任务可能需要不同类型和数量的训练数据。某些模型对数据量和质量要求更高。

   - **预训练模型的特性**：BERT、LLaMA和ChatGLM等模型在预训练时采用不同的目标任务和数据集，因此它们可能在不同类型的任务上表现更好。
   ## 4.各个专业领域是否需要各自的大模型来服务
      不一定需要每个专业领域都有自己的大模型。通用的大型语言模型（如GPT-3、LLaMA、BERT）在许多不同领域都表现出色，并可以用于多种任务。然而，对于某些特定领域或任务，领域特定的模型可能会更有优势，因为它们经过专门的训练，可以更好地理解和处理领域特定的术语和语境。

在一些特定领域，如医学、法律、金融等，已经涌现出一些领域特定的模型或预训练模型，它们在相应领域的任务上具有更好的性能。因此，是否需要领域特定的大模型取决于任务的性质、可用数据和性能要求。通常，通用模型可用于多个领域，但在某些情况下，领域特定的模型可能更适合。
   ## 5.如何让大模型处理更长的文本
      要让大模型处理更长的文本，可以考虑以下方法：

   - **切分文本**：将长文本切分成较小的片段，然后分别处理这些片段。可以使用特殊分隔符来标识文本片段之间的边界，以确保模型在处理时能够理解这些边界。
   
   - **滑动窗口**：使用滑动窗口的方法，将模型应用于文本的不同部分，以捕捉全文的上下文。通过在窗口内滑动，模型可以依次处理文本的各个部分。

   - **硬件升级**：使用更大内存的GPU或分布式计算集群等更强大的硬件资源，以处理更长的文本。这需要更多的计算资源来容纳大型模型的参数和上下文。

   - **自定义模型**：有时，可能需要自定义大型模型，以使其专门针对处理长文本进行优化。这可以包括修改模型的架构或训练任务，以适应长文本的需求。

   - **特殊标记**：可以使用特殊标记或标签来标识文本中的关键部分，以引导模型关注或处理这些部分。

   总之，处理更长的文本需要考虑切分、滑动窗口、硬件资源和特殊标记等方法，具体取决于任务的性质和可用资源。
   # 大模型（LLMs）微调面
   全参数微调显存需求: 显存需求取决于模型的大小和架构，通常来说，全参数微调需要大量显存，尤其是针对大型语言模型。一般来说，至少需要数十GB的显存，但更大的模型可能需要更多。具体的显存需求还取决于微调的任务和数据。

SFT和LLM性能: SFT（Sparse Feature Training）指的是在微调时使用稀疏特征作为模型的输入。有时，SFT之后模型可能表现出更加保守、不创造性的特点，因为它依赖于输入的稀疏特征来生成输出，而不像传统的LLMs那样自由生成文本。

SFT指令微调数据构建: SFT指令微调数据通常由领域专家根据任务需求来构建，包括定义特征、标签、输入格式等。这些数据可以是手动标记的，也可以是从现有的数据中提取的。

领域模型Continue PreTrain数据选取: 领域模型的Continue PreTrain数据应该包括与目标领域相关的大规模文本数据，以便模型能够在该领域上获得更多知识。数据的选择应根据任务和领域的需求，包括新闻文章、专业文献、领域内的对话等。

缓解模型遗忘通用能力: 为了缓解模型在领域微调后遗忘通用能力，可以使用一些技术，如多任务学习、领域适应、渐进学习等，以确保模型在领域特定任务和通用任务之间取得平衡。

领域模型Continue PreTrain知识注入: 在领域模型的Continue PreTrain过程中，模型会通过在大规模领域相关数据上训练来获得更多知识。这包括领域内的术语、语法结构、主题知识等。

SFT操作基座模型选择: 基座模型的选择通常取决于任务的性质和需求。如果任务需要模型生成文本，Chat模型可能更合适。如果任务是分类等非生成任务，Base模型可能更适用。

领域模型微调指令&数据输入格式要求: 领域模型微调的指令通常包括定义任务、特征、标签和损失函数等。数据输入格式要求根据任务和模型的需求而定，通常需要与指令中定义的特征和标签相匹配。

领域模型微调领域评测集构建: 领域评测集应该由领域专家或任务相关的人员构建，包括输入样本和对应的标签或参考答案。评测集的构建需要遵循任务的评估标准和指标。

领域模型词表扩增: 词表扩增有时是有必要的，特别是在领域模型中包含领域特定术语或实体时。这可以通过将领域内的词汇添加到模型的词表中来实现。

训练自己的大模型: 训练自己的大模型需要大规模的数据、高性能的硬件和深度学习知识。这通常需要云计算资源或大规模的计算集群，以及对模型架构、训练过程和数据处理的深入理解。

中文大模型训练经验: 中文大模型的训练需要大规模的中文语料库，以及对中文文本特点的理解。合理的分词和预处理是至关重要的。

指令微调的好处: 指令微调可以用来将模型引导到执行特定任务，以确保生成的文本符合任务需求。这有助于提高模型在特定任务上的性能。

预训练和微调的知识注入: 预训练阶段注入了通用知识，微调阶段注入了特定任务或领域的知识。这两个阶段结合起来使模型适用于各种任务。

学习领域知识的阶段: 想让模型学习某个领域或行业的知识，通常应该在微调阶段引入领域特定的数据和指令，以便模型能够适应该领域的任务。

多轮对话任务微调: 在多轮对话任务中，可以使用对话数据集进行微调，引导模型生成连贯的对话。此外，可以采用多任务学习，同时微调多轮对话和单轮对话任务，以提高性能。

能力劣化和灾难性遗忘: 模型微调后出现能力劣化和灾难性遗忘可能是由于微调任务与预训练任务不一致，导致模型遗忘了通用能力。使用合适的训练技巧，如渐进学习和知识蒸化，可以减轻这种问题。

化，可以减轻这种问题。

微调模型显存需求: 微调模型的显存需求取决于模型的大小和任务的复杂性。通常，微调较小的模型需要较少的显存，而微调大型模型需要更多显存。一般来说，至少需要几GB的显存，但对于大型模型，可能需要更多。

大模型SFT学习: 在进行SFT（Sparse Feature Training）操作时，大模型LLM可以学习如何利用稀疏特征来生成文本，以满足特定任务的需求。这可以包括对输入特征进行映射，以生成相关的输出文本。

预训练和SFT的不同: 预训练是在大规模文本上进行的通用语言模型的训练，目的是使模型具备通用语言理解和生成能力。SFT是在预训练的基础上，通过微调和引入稀疏特征来使模型适应特定任务。

样本量增大导致OOM错误: 样本量增大可能导致内存溢出（OOM）错误，因为更多的样本需要更多的内存来进行处理。解决方法可以包括减小批处理大小、使用分布式训练、增加硬件资源等。

SFT样本优化: 对于SFT，优化样本通常涉及选择和设计适当的特征，以确保模型能够从这些特征中获得有用的信息。这可能需要领域专家的参与，以确定哪些特征对任务最有帮助。

模型参数迭代实验: 模型参数迭代实验是指通过多次微调和调整模型参数，以逐步改进模型性能的过程。这涉及尝试不同的参数配置、训练策略和数据处理方法，以找到最佳的模型性能。
